\chapter{asyncio异步编程模型}

传统的线程与进程模型在处理数以千计的并发I/O连接时，往往因较高的资源开销与上下文切换成本而导致效率低下。Python的asyncio框架采用基于单线程的协作式多任务异步编程模型，为高并发爬虫、Web服务器等I/O密集型场景提供了更为理想的解决方案。

\section{异步编程的核心：协程}

\subsection{async/await语法与协程原理}

\index{协程}\index{Coroutine}协程（Coroutine）是asyncio异步编程的基本构建块，它是一种特殊的函数，能够在执行过程中主动暂停，并将控制权交还给调度器，随后在恰当的时机从暂停点恢复执行。

与操作系统线程的抢占式调度不同，协程采用协作式调度方式，主动通过\inlinepython{await}表达式让出控制权，而非被强制中断。相对比而言，线程切换发生在操作系统的内核态，需要保存/恢复完整的CPU上下文，如寄存器、栈指针等，涉及系统调用开销；协程切换完全在用户态进行，仅需保存程序计数器、栈指针等少量状态，开销通常为线程切换的百分之一甚至千分之一。

下面的代码展示了协程的基本定义与行为：

\begin{minted}[escapeinside=||]{python}
# file: src/fxb/ch08/coroutine_basic.py
import asyncio

async def simple_coroutine(name: str, delay: float) -> float:
    """简单的协程示例"""
    print(f"[{name}] 开始执行，等待 {delay} 秒")
    await asyncio.sleep(delay)  # 模拟异步 I/O 操作
    print(f"[{name}] 执行完成")
    return delay*10

async def demonstrate_coroutines():
    """演示协程的基本行为"""
    coro1 = simple_coroutine("协程1", 2.0) |\label{code:coroutine:basic:1}|
    coro2 = simple_coroutine("协程2", 1.0)

    print(f"coro1 类型: {type(coro1)}")

    # 使用 await 顺序执行协程
    result1 = await coro1
    result2 = await coro2
    print(f"结果: {result1}, {result2}")

if __name__ == "__main__":
    asyncio.run(demonstrate_coroutines())
\end{minted}

运行上述代码，输出如下：

\begin{minted}{text}
coro1 类型: <class 'coroutine'>
[协程1] 开始执行，等待 2.0 秒
[协程1] 执行完成
[协程2] 开始执行，等待 1.0 秒
[协程2] 执行完成
结果: 20.0, 10.0
\end{minted}

在理解协程的行为时，需要明确几个关键概念：

首先，使用\inlinepython{async def}定义的函数称为协程函数。调用协程函数不会立即执行其内部代码，而是返回一个协程对象。例如，上面代码中的第\ref{code:coroutine:basic:1}行返回的是一个类型为\inlinepython{coroutine}的对象，而不是函数直接执行的结果。这是因为协程函数的执行是由事件循环来驱动的，而不是传统的函数调用。事件循环的详细信息请参考\ref{sec:coroutine:evevnt_loop}节。

其次，\inlinepython{await}关键字只能在协程函数内部使用。它是一个暂停点，其后通常跟随一个可等待对象，如 \inlinepython{asyncio.sleep()}。当执行到\inlinepython{await}表达式时，当前协程会主动暂停，将控制权交还给事件循环，直到等待的操作完成，协程才从此处恢复并获取结果。

最后，\inlinepython{asyncio.run()}作为asyncio程序的入口，负责创建并管理一个事件循环，执行传入的顶层协程。事件循环是协程的调度中枢，负责在适当的时机（如 I/O 操作完成时）唤醒并恢复等待中的协程。

%简单来说，协程通过用户态协作式调度这一核心机制，避免了操作系统线程切换的相对高额开销与复杂性。它允许在单线程内高效处理成千上万的并发I/O操作，是构建高并发、高性能网络应用的基础。


\subsection{从顺序到并发：理解await与任务创建}

默认情况下，多个\inlinepython{await}是顺序执行的。要实现真正的并发，需要创建任务。任务是事件循环对协程的进一步封装，它负责调度协程的执行，并允许它们在事件循环中并发运行。

下面的示例展示了顺序执行与并发执行的区别：

\begin{minted}{python}
# file: src/fxb/ch08/task_concurrency.py
import asyncio
import time

async def say_after(delay: float, message: str):
    await asyncio.sleep(delay)
    print(message)
    return delay

async def sequential_execution():
    """顺序执行"""
    start_time = time.time()
    r1 = await say_after(1.0, "第一个消息")
    r2 = await say_after(1.0, "第二个消息")
    print(f"顺序执行结果: {r1}, {r2}, 耗时: {time.time() - start_time:.2f} 秒")

async def concurrent_execution():
    """并发执行"""
    start_time = time.time()
    task1 = asyncio.create_task(say_after(1.0, "第一个消息"))
    task2 = asyncio.create_task(say_after(1.0, "第二个消息"))

    r1 = await task1
    r2 = await task2
    print(f"并发执行结果: {r1}, {r2}, 耗时: {time.time() - start_time:.2f} 秒")

async def main():
    await sequential_execution()
    print()
    await concurrent_execution()

if __name__ == "__main__":
    asyncio.run(main())
\end{minted}

运行上述代码，可以看到顺序执行需要约2秒完成，而并发执行仅需约1秒。关键区别在于，\inlinepython{asyncio.create\_task()} 会将协程包装为任务并立即调度到事件循环中，使其能够并发执行，而非等待前一个任务完成。

\section{事件循环与任务管理}
\label{sec:coroutine:evevnt_loop}

\subsection{事件循环的核心职责}

事件循环（Event Loop）是整个asyncio框架的核心，它负责调度协程的执行，管理I/O事件。在单线程环境中，事件循环采用事件驱动的方式，通过轮询和回调机制监控所有I/O事件和任务状态，以此决定协程的执行顺序。

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{figures/event_loop.pdf}
\caption{事件循环}
\label{fig:event_loop}
\end{figure}

事件循环的基本流程如图\ref{fig:event_loop}所示。首先，主线程将任务提交到任务队列。其次，事件循环持续监控任务队列并运行任务，直至遇到I/O任务。此时，事件循环会暂停该任务并将其交由操作系统处理。第三，检查已完成的I/O任务。若任务完成，操作系统会通知程序，随后事件循环继续运行已恢复的任务。上述步骤会不断重复，直至任务队列为空。

每个线程通常有一个主事件循环，可以通过 \inlinepython{asyncio.get\_event\_loop()} 获取。但现代 asyncio 代码通常使用 \inlinepython{asyncio.run()} 作为入口，它会自动创建和管理事件循环。

\subsection{任务的创建与运行}

任务是对协程的进一步封装，它代表一个正在事件循环中执行的协程。创建任务后，事件循环会开始调度它的执行，而无需立即使用 \inlinepython{await} 等待。

下面的示例展示了任务的基本操作：

\begin{minted}[escapeinside=||]{python}
# file: src/fxb/ch08/task_management.py
import asyncio

async def long_running_task(name: str, seconds: int)->str:
    print(f"任务 {name} 开始，需要 {seconds} 秒")
    await asyncio.sleep(seconds)
    print(f"任务 {name} 完成")
    return f"{name}:{seconds}"

async def main():
    # 创建任务
    task_a = asyncio.create_task(long_running_task("A", 3)) | \label{code:async:task:1}|
    task_b = asyncio.create_task(long_running_task("B", 2))
    task_c = asyncio.create_task(long_running_task("C", 1))
    
    print("所有任务已创建，开始并发执行...")
    
    # 等待所有任务完成，并收集结果
    results = await asyncio.gather(task_a, task_b, task_c) | \label{code:async:task:2}|
    print(f"所有任务完成，结果: {results}")

if __name__ == "__main__":
    asyncio.run(main())
\end{minted}

在上面的示例中，我们使用\inlinepython{asyncio.create\_task()}函数创建了三个任务，它们分别代表三个并发执行的协程。\inlinepython{create\_task()}会将协程封装为任务并立即提交给事件循环进行调度。随后，我们使用\inlinepython{asyncio.gather()} 等待所有任务完成，并收集它们的返回结果。

执行上述代码后，输出结果如下：

\begin{minted}{text}
所有任务已创建，开始并发执行...
任务 A 开始，需要 3 秒
任务 B 开始，需要 2 秒
任务 C 开始，需要 1 秒
任务 C 完成
任务 B 完成
任务 A 完成
所有任务完成，结果: ['A:3', 'B:2', 'C:1']
\end{minted}

从输出可以看出，三个任务几乎是同时开始的，但完成顺序取决于各自的执行时间。另外，
\inlinepython{asyncio.gather()}是asyncio中用于并发执行多个可等待对象并收集其结果的函数，可等待对象既可以是\inlinepython{create\_task()}创建的任务，也可以是协程对象。如果是协程对象，\inlinepython{gather()}会同时启动该任务，确保对象并发执行。即上述代码中的第\ref{code:async:task:1} \textasciitilde \ref{code:async:task:2}行代码，可以替换为：

\begin{minted}{python}
results = await asyncio.gather(
    long_running_task("A", 3),
    long_running_task("B", 2),
    long_running_task("C", 1),
)
\end{minted}    

任务提供了比简单协程更丰富的控制能力，例如可以取消任务、设置超时、检查任务状态等，更多示例将在第\ref{sec:async-task-management}节介绍。

\subsection{结构化并发}

Python 3.11引入了\inlinepython{asyncio.TaskGroup}，提供了更安全的结构化并发管理方式。\inlinepython{TaskGroup}确保组内所有任务都被妥善管理，当一个任务失败时，会自动取消其他任务，避免资源泄漏。

\begin{minted}[escapeinside=||]{python}
# file: src/fxb/ch08/task_group.py (Python 3.11+)
import asyncio

async def worker(name: str, delay: float)->str:
    print(f"{name} 开始工作")
    await asyncio.sleep(delay)
    if name == "B" and delay > 1:
        raise ValueError(f"{name} 出错了!")
    print(f"{name} 工作完成")
    return f"{name} 结果"

async def main():
    try:
        async with asyncio.TaskGroup() as tg:
            # 创建任务组内的任务
            t1 = tg.create_task(worker("A", 1.5))
            t2 = tg.create_task(worker("B", 2.5))  # 这个会出错, 改成0.5则正常 |\label{code:async:taskgroup:1}|
            t3 = tg.create_task(worker("C", 0.5))

        # 如果所有任务成功完成，继续执行
        print(f"所有任务成功: {t1.result()}, {t2.result()}, {t3.result()}") |\label{code:async:taskgroup:2}|
    except* ValueError as eg:
        # 处理部分任务失败的情况
        for exc in eg.exceptions:
            print(f"任务出错: {exc}")

if __name__ == "__main__":
    asyncio.run(main())
\end{minted}

上述代码使用 \inlinepython{async with asyncio.TaskGroup() as tg:} 语句创建了一个任务组上下文管理器。在该上下文中，通过 \inlinepython{tg.create\_task()} 创建的任务会被自动管理。任务组会等待所有任务完成，并在出现异常时自动取消尚未完成的任务，确保资源得到正确释放。

上面代码执行后，输出如下：

\begin{minted}{text}
A 开始工作
B 开始工作
C 开始工作
C 工作完成
A 工作完成
任务出错: B 出错了!
\end{minted}

运行结果表明，任务C先完成，然后是任务A。任务B因抛出异常，导致整个任务组失败，因此没有运行到第\ref{code:async:taskgroup:2}行代码。如果将第\ref{code:async:taskgroup:1}的\inlinepython{delay}改为0.5，则可以正常执行完毕，读者可以自己尝试。


\section{异步任务的超时、取消与异常处理}
\label{sec:async-task-management}

健壮的异步系统需要处理任务运行时的不确定性。表\ref{tab:async-error-handling}总结了异步任务中常见的问题及处理策略。

\begin{table}[htbp]
  \centering
  \small
  \caption{异步任务常见问题及处理策略}
  \label{tab:async-error-handling}
    \begin{tabular}{@{}>{\centering\arraybackslash}p{2cm} p{3cm} p{7cm}@{}}
        \toprule
        问题类型 & 表现 & 处理策略 \\
        \midrule
        超时 & 任务执行时间过长 & 使用asyncio.wait\_for() 设置超时 \\
        取消 & 任务需要被中断 & 捕获asyncio.CancelledError \\
        异常 & 任务执行出错 & 使用try-except或设置return\_exceptions参数 \\
        资源泄漏 & 未正确释放资源 & 使用async with管理资源 \\
        \bottomrule
  \end{tabular}
\end{table}

\subsection{超时控制}

在异步编程中，设置合理的超时时间是保证系统稳定性的重要手段。asyncio框架提供了 \inlinepython{asyncio.wait\_for()} 函数，用于为异步操作设置超时时间，防止任务因网络延迟、资源竞争等原因无限制等待。

\begin{minted}{python}
# file: src/fxb/ch08/timeout_example.py
import asyncio

async def slow_operation(delay: float):
    await asyncio.sleep(delay)
    return f"操作完成，耗时 {delay} 秒"

async def main():
    try:
        # 设置超时为 1.5 秒
        result = await asyncio.wait_for(slow_operation(2.0), timeout=1.5)
        print(f"成功: {result}(delay=2.0)")
    except asyncio.TimeoutError:
        print("操作超时！(delay=2.0)")

    # 成功的情况
    try:
        result = await asyncio.wait_for(slow_operation(1.0), timeout=1.5)
        print(f"成功: {result}(delay=1.0)")
    except asyncio.TimeoutError:
        print("操作超时！(delay=1.0)")

if __name__ == "__main__":
    asyncio.run(main())
\end{minted}

上述代码演示了\inlinepython{asyncio.wait\_for()} 的两种典型场景。第一个任务需要2.0秒完成，但设置的超时时间为1.5秒，因此会抛出 \inlinepython{asyncio.TimeoutError} 异常。第二个任务只需1.0秒，因此在超时时间内顺利完成并返回结果。

\subsection{任务取消}

任务可以通过\inlinepython{cancel()}方法取消，当一个任务被取消时，它会在当前挂起的\inlinepython{await}处抛出一个 \inlinepython{asyncio.CancelledError} 异常。任务可以捕获这个异常，执行资源清理操作，然后重新抛出该异常（这是推荐的做法），以确保任务的正式取消。

下面的示例展示了任务取消的基本流程：

\begin{minted}[escapeinside=||]{python}
# file: src/fxb/ch08/cancel_example.py
import asyncio

async def cancellable_task():
    try:
        print("任务开始")
        await asyncio.sleep(5)  # 模拟长时间运行
        print("任务正常完成")
        return "结果"
    except asyncio.CancelledError:
        print("任务被取消，正在清理资源...")
        raise  # 重新抛出异常是标准做法

async def main():
    task = asyncio.create_task(cancellable_task())

    # 等待1秒后取消任务,此时任务还没有结束，因此会抛出异常
    await asyncio.sleep(1) | \label{code:async:cancel:1}|
    task.cancel()

    try:
        await task
    except asyncio.CancelledError:
        print("主函数中捕获到取消异常")

if __name__ == "__main__":
    asyncio.run(main())
\end{minted}

在上述代码中，\inlinepython{cancellable\_task()} 函数模拟了一个需要5秒才能完成的长时间运行任务。主函数创建任务后，等待1秒后调用 \inlinepython{task.cancel()} 来取消任务。被取消的任务会抛出\inlinepython{CancelledError} 异常，该异常可以被任务自身捕获以进行资源清理，然后重新抛出，最终在主函数中被捕获。

如果将第\ref{code:async:cancel:1}行的\inlinepython{await asyncio.sleep(1)}改为\inlinepython{await asyncio.sleep(10)}，即10秒后取消任务，但由于此时任务已经正常完成，因此最终不会抛出\inlinepython{CancelledError}异常，读者可自己修改代码进行测试。


\subsection{异常传播}

当使用 \inlinepython{asyncio.gather()} 并发执行多个任务时，默认情况下，任何一个任务抛出异常都会导致整个 gather 调用抛出异常。可以通过 \inlinepython{return\_exceptions=True} 参数改变这一行为，使所有任务的异常作为结果返回。

\inlinepython{asyncio.gather()}函数提供了两种异常处理模式，让开发者能够灵活控制异常传播行为。在默认情况下，\inlinepython{asyncio.gather()} 采用快速失败策略：如果任何一个任务抛出异常，整个\inlinepython{gather()}调用会立即抛出该异常，其他任务仍然会继续执行但结果会被忽略。

在某些场景下，我们可能希望收集所有任务的执行结果，包括异常。这时可以使用 \inlinepython{return\_exceptions=True}参数，让异常作为正常结果返回，便于进一步处理。

下面的示例对比了这两种模式：

\begin{minted}{python}
# file: src/fxb/ch08/exception_handling.py
from typing import NoReturn
import asyncio


async def task_with_result(name: str, result: str)->str:
    return f"{name}: {result}"


async def task_with_exception(name: str)->NoReturn:
    raise ValueError(f"{name} 抛出了异常")


async def main():
    tasks = [
        task_with_result("A", "成功"),
        task_with_exception("B"),
        task_with_result("C", "成功"),
    ]

    # 默认行为：遇到异常立即抛出，此时得不到results信息
    try:
        results = await asyncio.gather(*tasks)
    except ValueError as e:
        print(f"默认模式捕获到异常: {e}")

    # 返回异常模式，任务需重新实例化，否则提示：cannot reuse already awaited coroutine
    tasks = [
        task_with_result("A", "成功"),
        task_with_exception("B"),
        task_with_result("C", "成功"),
    ]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    print("\n使用 return_exceptions=True 的结果:")
    for i, r in enumerate(results):
        if isinstance(r, Exception):
            print(f"任务 {i}: 异常 - {r}")
        else:
            print(f"任务 {i}: 成功 - {r}")


if __name__ == "__main__":
    asyncio.run(main())
\end{minted}

执行上述代码后，输出如下：
\begin{minted}{text}
默认模式捕获到异常: B 抛出了异常

使用 return_exceptions=True 的结果:
任务 0: 成功 - A: 成功
任务 1: 异常 - B 抛出了异常
任务 2: 成功 - C: 成功
\end{minted}

选择合适的异常处理模式取决于具体的应用场景。遇到异常立即抛出的默认模式适用于任务之间存在依赖关系的情况，当一个任务的失败意味着其他任务已无继续执行的必要时，这种模式可以快速终止整个操作，避免不必要的资源消耗。返回异常模式则适用于需要完整收集所有任务执行结果的场景，例如批量数据处理、系统状态监控或并行检查等，此时异常被视为一种特殊的结果形式，不会中断其他任务的执行。

无论选择哪种处理模式，都应当确保异常得到妥善处理，避免未捕获的异常导致整个应用程序意外崩溃。


\section{异步与同步代码的混合调用}

在大型项目的开发与维护中，异步代码与同步代码并存是常见现象。为了在保持向后兼容的同时充分利用异步编程的优势，开发者需要掌握异步与同步代码之间的边界跨越技术。asyncio提供了多种工具来优雅地桥接这两种编程范式。

\subsection{在异步代码中调用同步代码}

由于同步代码在执行时会阻塞当前线程，直接在异步上下文中调用可能会阻塞整个事件循环，从而降低异步系统的响应性。为避免这一问题，可以使用\inlinepython{asyncio.to\_thread()} 函数，将同步函数转移到单独的线程中执行，从而避免阻塞主事件循环。

下面的示例展示了如何安全地在异步代码中调用同步阻塞函数：

\begin{minted}{python}
# file: src/fxb/ch08/async_to_sync.py
import asyncio
import time

def synchronous_blocking_function(duration: float) -> str:
    """模拟耗时的同步函数"""
    time.sleep(duration)
    return f"同步函数完成，耗时 {duration} 秒"

async def main():
    # 错误方式：直接调用会阻塞事件循环
    # result = synchronous_blocking_function(1.0)
    
    # 正确方式：使用 to_thread 在单独线程中执行
    result = await asyncio.to_thread(synchronous_blocking_function, 1.0)
    print(f"结果: {result}")
    
    # 并发执行多个同步函数
    tasks = [
        asyncio.to_thread(synchronous_blocking_function, 1.5),
        asyncio.to_thread(synchronous_blocking_function, 1.0),
        asyncio.to_thread(synchronous_blocking_function, 0.5),
    ]
    
    results = await asyncio.gather(*tasks)
    for r in results:
        print(f"并发结果: {r}")

if __name__ == "__main__":
    asyncio.run(main())
\end{minted}

通过\inlinepython{asyncio.to\_thread()}，同步函数可以在独立的线程池中执行，不会阻塞主事件循环。当同步函数完成时，其结果会被传递回异步上下文，从而实现了异步与同步代码的无缝集成。需要注意的是，频繁使用此方法可能会因线程切换带来额外开销，因此应将其用于确实无法异步化的同步代码。

\subsection{在同步代码中调用异步代码}

在同步代码中调用异步函数时，需要启动一个事件循环来执行异步操作。asyncio提供了两种主要方法：推荐使用\inlinepython{asyncio.run()}作为简单入口，或在需要更精细控制时手动管理事件循环。

下面的示例展示了两种从同步代码调用异步函数的方法：

\begin{minted}{python}
# file: src/fxb/ch08/sync_to_async.py
import asyncio

async def async_function(name: str, delay: float) -> str:
    await asyncio.sleep(delay)
    return f"{name} 完成，等待 {delay} 秒"

# 方法1：使用 asyncio.run()（推荐）
def sync_caller_1():
    print("同步代码调用异步函数...")
    result = asyncio.run(async_function("任务A", 1.0))
    print(f"结果: {result}")

# 方法2：手动管理事件循环（不推荐）
def sync_caller_2():
    print("手动管理事件循环...")
    loop = asyncio.new_event_loop()
    
    try:
        result = loop.run_until_complete(async_function("任务B", 0.5))
        print(f"结果: {result}")
    finally:
        loop.close()

if __name__ == "__main__":
    sync_caller_1()
    print()
    sync_caller_2()
\end{minted}

第一种方法使用\inlinepython{asyncio.run()}，它会自动创建并管理事件循环，执行完成后自动清理资源，是最简单安全的方式。但需要注意的是，\inlinepython{asyncio.run()}不能在一个已有事件循环运行的线程中调用。

第二种方法提供了更精细的控制，适用于需要复用事件循环或进行复杂调度的场景。通过手动创建事件循环，调用\inlinepython{run\_until\_complete()}来执行异步函数，最后需要显式关闭循环以释放资源。这种方法需要开发者谨慎管理事件循环的生命周期，避免资源泄漏。


\section{异步I/O库}

要充分利用 asyncio 的并发优势，开发者需要选择专门为异步编程设计的I/O库。这些库底层使用非阻塞I/O操作，能够与asyncio事件循环无缝协作，从而在单线程内高效处理大量并发请求。表\ref{tab:async-libraries}列举了一些常用的异步 I/O 库及其典型应用场景。

\begin{table}[htbp]
  \centering
  \small
  \caption{常用异步 I/O 库}
  \label{tab:async-libraries}
    \begin{tabular}{@{}>{\centering\arraybackslash}p{2cm} p{4cm} p{6cm}@{}}
        \toprule
        库名 & 类型 & 主要用途 \\
        \midrule
        HTTPX & HTTP 客户端 & 支持HTTP/2的异步HTTP请求 \\
        FastAPI & Web 框架 & 异步Web框架 \\
        aiocache & 缓存 & 异步缓存库 \\
        aiofiles & 文件 I/O & 异步文件操作 \\
        aiomysql & 数据库 & 基于PyMySQL的异步驱动 \\
        AIOHTTP & HTTP服务器/客户端 & 完整的异步HTTP生态 \\
        \bottomrule
  \end{tabular}
\end{table}

有关这些库的详细用法，请参阅各自的官方文档。本节仅以HTTPX和aiofiles为例，简要展示异步I/O库在实践中的使用方法。


\subsection{异步HTTP请求：HTTPX}

HTTPX\footnote{\url{https://www.python-httpx.org}} 是一个功能丰富的HTTP客户端库，支持HTTP/1.1和HTTP/2协议，并提供了同步与异步两套API。其异步API完全基于asyncio构建，适合在高并发场景下进行网络请求。

可通过以下命令安装 HTTPX：

\begin{minted}{bash}
uv add httpx
# 或使用 pip: pip install httpx
\end{minted}

以下示例演示了如何使用HTTPX异步并发请求多个URL：

\begin{minted}{python}
# file: src/fxb/ch08/async_http.py
import asyncio
import httpx

async def fetch_url(client: httpx.AsyncClient, url: str):
    """异步获取URL内容"""
    try:
        response = await client.get(url, timeout=10.0)
        return url, response.status_code, len(response.text)
    except Exception as e:
        return url, str(e), 0

async def main():
    urls = [
        "https://httpbin.org/get",
        "https://httpbin.org/delay/1",
        "https://httpbin.org/status/404",
    ]
    
    async with httpx.AsyncClient() as client:
        tasks = [fetch_url(client, url) for url in urls]
        results = await asyncio.gather(*tasks)
        
        for url, status, length in results:
            print(f"{url}: 状态={status}, 长度={length}")

if __name__ == "__main__":
    asyncio.run(main())
\end{minted}

在上述示例中，我们使用\inlinepython{httpx.AsyncClient}上下文管理器确保连接可以正确关闭，并通过\inlinepython{asyncio.gather()}并发执行多个请求，从而提高程序在I/O等待期间的效率。

\subsection{异步文件操作：aiofiles}

aiofiles\footnote{\url{https://github.com/Tinche/aiofiles}} 提供了异步文件操作接口，使得读写文件时不会阻塞事件循环。该库的API设计尽可能与Python内置的 \inlinepython{open()}函数保持一致，降低了学习成本。

可通过以下命令安装aiofiles：

\begin{minted}{bash}
uv add aiofiles
# 或使用 pip: pip install aiofiles
\end{minted}

以下示例展示了如何使用aiofiles并发读写文件：

\begin{minted}{python}
# file: src/fxb/ch08/async_file.py
import os
import asyncio
import aiofiles

async def write_file(filename: str, content: str):
    """异步写入文件"""
    async with aiofiles.open(filename, "w") as f:
        await f.write(content)
    print(f"已写入文件: {filename}")

async def read_file(filename: str):
    """异步读取文件"""
    async with aiofiles.open(filename, "r") as f:
        content = await f.read()
    print(f"从 {filename} 读取到 {len(content)} 字符")
    return content

async def main():
    # 并发执行文件操作
    await asyncio.gather(
        write_file("test1.txt", "Hello, asyncio!\n"),
        write_file("test2.txt", "Another file.\n"),
    )

    # 并发读取文件
    c1, c2 = await asyncio.gather(
        read_file("test1.txt"),
        read_file("test2.txt"),
    )
    assert c1 == "Hello, asyncio!\n"  # 验证内容
    assert c2 == "Another file.\n" 

    # 清理临时文件
    os.remove("test1.txt")
    os.remove("test2.txt")

if __name__ == "__main__":
    asyncio.run(main())
\end{minted}

与同步文件操作相比，使用aiofiles可以在等待磁盘I/O时让出控制权，使事件循环能够处理其他任务，从而提高程序的整体吞吐量。

选择合适的异步I/O库是构建高效异步应用的关键。随着Python异步生态的日益成熟，越来越多的传统库开始提供异步版本，为开发者提供了丰富的选择。


\section*{本章总结与进阶思考}

asyncio 模型是 Python 处理高并发 I/O 密集型任务的未来。通过理解协程、事件循环和 async/await 的协作机制，你能够构建出比传统线程/进程模型更高效、资源占用更少的应用。随着异步编程在 Python 生态系统中的普及，越来越多的库开始提供原生异步支持。在构建新系统时，可以优先考虑基于 asyncio 的架构。对于现有系统，可以通过逐步迁移的方式引入异步组件。同时，注意异步编程带来的复杂性，合理使用工具和模式来保持代码的可维护性。

\textbf{关键要点回顾：}
\begin{itemize}
    \item 协程是 asyncio 的基本构建块，通过 async/await 语法实现协作式多任务。
    \item 事件循环是 asyncio 的核心调度器，负责管理所有协程和 I/O 事件。
    \item 任务是对协程的封装，支持并发执行、取消和状态查询。
    \item 结构化并发（TaskGroup）提供了更安全的并发任务管理方式。
    \item 合理的超时、取消和异常处理是构建健壮异步系统的关键。
    \item 异步与同步代码的混合调用需要遵循特定模式，避免阻塞事件循环。
    \item 异步I/O 库（如HTTPX、aiofiles）是构建高效异步应用的基础。
\end{itemize}


\textbf{进阶思考：}

asyncio 为I/O密集型应用提供了高效的解决方案。下一章，我们将学习如何使用性能剖析工具来诊断程序瓶颈，让优化工作有的放矢。